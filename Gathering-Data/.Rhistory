rep(c(0, 5), 5)
hh = hclust(dist(dataMatrix))
dataMatrixOrdered = dataMatrix[hh$order,]
svd2 = svd(scale(dataMatrixOrdered))
par(mfrow=c(1,3))
image(t(dataMatrixOrdered) [, nrow(dataMatrixOrdered):1])
plot(rep(c(0,1), each = 5), pch = 19, xlab="Column", ylab="Pattern 1")
plot(rep(c(0, 1), 5), pch=19, xlab=:"Column", ylab="Pattern 2")
svd2 = svd(scale(dataMatrixOrdered))
par(mfrow=c(1,3))
image(t(dataMatrixOrdered) [, nrow(dataMatrixOrdered):1])
plot(rep(c(0,1), each = 5), pch = 19, xlab="Column", ylab="Pattern 1")
plot(rep(c(0, 1), 5), pch=19, xlab=:"Column", ylab="Pattern 2")
plot(rep(c(0, 1), 5), pch=19, xlab="Column", ylab="Pattern 2")
scale(dataMatrixOrdered)
svd2 = svd(scale(dataMatrixOrdered))
par(mfrow=c(1,3))
image(t(dataMatrixOrdered) [, nrow(dataMatrixOrdered):1])
plot(svd2$v[, 1], pch = 19, xlab="Column", ylab="First right singular vector")
plot(svd$v[,2], pch=19, xlab="Column", ylab="Second right singular vector")
plot(svd2$v[,2], pch=19, xlab="Column", ylab="Second right singular vector")
svd1 <- svd(scale(dataMatrixOrdered))
par(mfrow = c(1, 2))
plot(svd1$d, xlab="Column", ylab = "Singular value", pch=19)
plot(svd1$d^2/sum(svd1$d^2), xlab="Column", ylab="Percent of variance explained")
plot(svd1$d^2/sum(svd1$d^2), xlab="Column", ylab="Percent of variance explained", pch=19)
svd1 <- svd(scale(dataMatrixOrdered))
par(mfrow = c(1, 2))
plot(svd1$d, xlab="Column", ylab = "Singular value", pch=19)
plot(svd1$d^2/sum(svd1$d^2), xlab="Column", ylab="Percent of variance explained", pch=19)
par(mar = rep(2, 4))
svd1 <- svd(scale(dataMatrixOrdered))
par(mfrow = c(1, 2))
plot(svd1$d, xlab="Column", ylab = "Singular value", pch=19)
plot(svd1$d^2/sum(svd1$d^2), xlab="Column", ylab="Percent of variance explained", pch=19)
par(mar = rep(4, 4))
svd1 <- svd(scale(dataMatrixOrdered))
par(mfrow = c(1, 2))
plot(svd1$d, xlab="Column", ylab = "Singular value", pch=19)
plot(svd1$d^2/sum(svd1$d^2), xlab="Column", ylab="Percent of variance explained", pch=19)
par(mar = c(2, 4, 4, 4))
svd1 <- svd(scale(dataMatrixOrdered))
par(mfrow = c(1, 2))
plot(svd1$d, xlab="Column", ylab = "Singular value", pch=19)
plot(svd1$d^2/sum(svd1$d^2), xlab="Column", ylab="Percent of variance explained", pch=19)
?mar
?par
par(mar=c(4, 4, 2, 4))
svd1 <- svd(scale(dataMatrixOrdered))
par(mfrow = c(1, 2))
plot(svd1$d, xlab="Column", ylab = "Singular value", pch=19)
plot(svd1$d^2/sum(svd1$d^2), xlab="Column", ylab="Percent of variance explained", pch=19)
dataMatrix = matrix(rnorm(400), nrow = 40)
image(1:10, 1:40, t(dataMatrix)[, nrow(dataMatrix):1])
set.seed(678910)
for (i in 1:40) {
#flip a coin
coinFlip = rbinom(1, size = 1, prob = 0.5)
if (coinFlip) {
# Some rows on the right will have a mean of 3, others will have a mean of 0
dataMatrix[i, ] <- dataMatrix[i, ] + rep(c(0, 3), each = 5)
}
}
image(1:10, 1:40, t(dataMatrix) [, nrow(dataMatrix):1])
heatmap(dataMatrix)
dataMatrix2 = dataMatrixOrdered
dataMatrix2[sample(1:100, size=40, replace=F)] <= NA
dataMatrix2 = dataMatrixOrdered
hh <- hclust(dist(dataMatrix))
dataMatrixOrdered <- dataMatrix[hh$order, ]
set.seed(12345)
par(mar = rep(0.2, 4))
dataMatrix = matrix(rnorm(400), nrow = 40)
image(1:10, 1:40, t(dataMatrix)[, nrow(dataMatrix):1])
heatmap(dataMatrix)
set.seed(678910)
for (i in 1:40) {
#flip a coin
coinFlip = rbinom(1, size = 1, prob = 0.5)
if (coinFlip) {
# Some rows on the right will have a mean of 3, others will have a mean of 0
dataMatrix[i, ] <- dataMatrix[i, ] + rep(c(0, 3), each = 5)
}
}
image(1:10, 1:40, t(dataMatrix) [, nrow(dataMatrix):1])
heatmap(dataMatrix)
hh <- hclust(dist(dataMatrix))
dataMatrixOrdered <- dataMatrix[hh$order, ]
dataMatrix2 = dataMatrixOrdered
dataMatrix2[sampele(1:100, size=40, replace=F), NA]
dataMatrix2[sample(1:100, size=40, replace=F)] <= NA
dataMatrix2[sample(1:100, size=40, replace=F)] <- NA
svd1 <- svd(scale(dataMatrix2))
library(impute)
install.packages("impute")
install.packages("Bioconductor")
install.packages("BioConductor")
install.packages("Biobase")
install.packages("BioBase")
library(bioclite)
load("data/face.rda")
source("http://bioconductor.org/biocLite.R")
biocLite()
library(impute) # bioconductor.org
biocLite("impute")
library(impute) # bioconductor.org
dataMatrix2 = dataMatrixOrdered
dataMatrix2[sample(1:100, size=40, replace=F)] <- NA
dataMatrix2 <- impute.knn(dataMatrix2)$data
svd1 = svd(scale(dataMatrixOrdered))
svd2 = svd(scale(dataMatrix2))
par(mfrow = c(1, 2)); plot(svd1$v[,1], pch=19); plot(svd$v[,1], pch=19)
par(mfrow = c(1, 2)); plot(svd1$v[,1], pch=19); plot(svd1$v[,1], pch=19)
load("data/face.rda")
image(t(faceData) [, nrow(faceData): 1])
p
pnor
pnorm
p.test
pval
pprob
pt
?pt
pt(1.984, df=286, ncp=1.96, lower.tail=T)
pt(1.962, df=574, ncp=1.96, lower.tail=T)
pt(1.962, df=574, lower.tail=T)
pt(1.962, df=574, ncp=1.96, lower.tail=T)
pt(1.962, df=574, lower.tail=F)
pt(1.962, df=574, ncp=1.96, lower.tail=T)
setwd("/Users/BrianSipple/Development/R/datasciencecoursera/Gathering-Data")
list.files()
housing = read.csv("./data/idaho_housing.csv")
names(housing)
strsplit("wgtp*")
regexp
reg
exp
?exp
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="./data/GDP", method="curl")
Rest = read.csv("./data/restaurants.csv")
names(Rest)
strsplit(names(Rest), "\\.")
strsplit(names(Rest), "\.")
strsplit(names(Rest), "\\.")
strsplit(names(housing), "wget")
strsplit(names(housing), "wgtp")
names(housing)
names(housing) == "wgtp."
names(housing) == "wgtp.+"
names(housing) == "wgtp^+"
find
?find
grep("wgtp", names(housing))
wgtpList = grep("wgtp", names(housing))
names(housing)[wgtpList]
strsplit( names(housing)[wgtpList], "wgtp" )
strsplit( names(housing)[wgtpList], "\wgtp" )
strsplit( names(housing)[wgtpList], "\\wgtp" )
strsplit( names(housing)[wgtpList], "p" )
strsplit( names(housing)[wgtpList], "p" )
splitted = strsplit( names(housing)[wgtpList], "p" )
names(housing)[wgtList] = splitted
names(housing)[wgtpList] = splitted
names(housing)
strsplit( names(housing)[wgtpList], "p" )
strsplit( names(housing)[wgtpList], "p" )
strsplit( names(housing)[wgtpList], "\p" )
strsplit( names(housing)[wgtpList], "\\p" )
strsplit( names(housing)[wgtpList], "\p\" )
strsplit( names(housing)[wgtpList], p )
strsplit( names(housing)[wgtpList], "p" )
strsplit( names(housing)[wgtpList], "wgtp" )
strsplit( names(housing)[wgtpList], "wgtp" )
strsplit( names(housing), "wgtp" )
housing = read.csv("./data/idaho_housing.csv")
names(housing)
strsplit( names(housing), "wgtp" )
names(housing) = strsplit(names(housing), "wgtp")
names(housing)
names(housing)[123]
GPD = read.csv("./data/GDP")
View(GPD)
?read
?read.table
GPD = read.table("./data/GDP", sep=",")
View(GPD)
grep("United", GDP$V$)
grep("United", GDP$V)
grep("United", GDP$V4)
GDP
GDP = read.table("./data/GDP", sep=",")
grep("United", GDP$V4)
grep("United$", GDP$V4)
grep("United$", list(GDP$V4))
grep("United", list(GDP$V4))
grep("^United", list(GDP$V4))
grep("*United", list(GDP$V4))
grep("*United", list(GDP$V4)), 2
grep("*United", list(GDP$V4), 2)
grep("*United", list(GDP$V4), 3)
grep("*United", list(GDP$V4), 4)
grep("^United", list(GDP$V4), 4)
list(GDP$V$)
list(GDP$V4)
GDP
gsub(",","",GDP)
list(GDP$V4)
GDP190 = read.csv("./data/gdp190.csv")
EDU = read.csc("./data/education190.csv")
EDU = read.csv("./data/education190.csv")
?merge
names(GDP190)
View(GDP190)
View(GDP190)
names(GDP190)[1] = "country_short_code"
View(EDU)
names(GDP190)[1] = "CountryCode"
merged = merge(GDP190, EDU, by = intersect(GDP190$CountryCode, EDU$CountryCode))
intersect(GDP190$CountryCode, EDU$CountryCode)
merged = merge(GDP190, EDU, by = intersect(as.character(GDP190$CountryCode), as.character(EDU$CountryCode)))
match
?match
install.package("quantmod")
install.packages("quantmod")
countryNames = GDP$V$
countryNames = GDP$V4
countryNames = GDP$V4
countryNames
rm
?rm
rm(list = ",", envir=GDP)
rm(list = ",", envir=as.environment(GDP))
as.environment(GDP)
for (i in 1: ncol(GDP)) {
rm(list=",", envir = as.environment(GDP[,i]))
}
for (i in 1: ncol(GDP)) {
rm(list=",", pos=-1,envir = as.environment(GDP[,i]))
}
character()
character(,)
character(",")
housing = read.csv("./data/idaho_housing.csv")
names(housing)
housing = read.csv("./data/idaho_housing.csv")
names(housing)
strsplit(names(housing), "wgtp")
strsplit(names(housing), "wgtp")[123]
as.numeric(countryNames)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="./data/GDP", method="curl")
GDP = read.table("./data/GDP", sep=",")
countryNames = GDP$V4
as.numeric(countryNames)
View(GDP)
View(GDP)
values = GDP$V5
values
as.numeric(values)
as.numeric(as.character(values))
as.character(values)
as.numeric(as.character(values))
values = as.character(values)
gsub(",", "", values)
values = gsub(",", "", values)
values = as.numeric(values)
values
mean(values)
?mean
mean(values, na.rm=T)
GDP = read.csv("./data/GDP")
View(GDP)
View(GDP)
values = GDP$X.3
values = as.character(values)
values = gsub(",", "", values)
values = as.numeric(values)
mean(values, na.rm=T)
mean(values, na.rm=F)
mean(values, na.rm=T)
names(GDP)[2] = "rank"
GDP = GDP[rank != NULL]
View(GDP)
View(GDP)
GDP = read.csv("./data/GDP")
names(GDP)[2] = "rank"
GDP[rank != NULL]
GDP[rank != NA]
GDP[ran]
GDP[rank]
names(GDP)[2] = "rank"
names(GDP)
GDP$rank != NULL
GDP$rank != NA
GDP$rank > 0
GDP$rank
GDP$rank = as.numeric(GDP$rank)
GDP$rank > 0
GDP$rank != NULL
GDP$rank = NULL
GDP$rank == NULL
GDP$rank == NA
GDP$rank == ""
= read.csv("./data/GDP")
n
= read.csv("./data/GDP")
n
GDP = read.csv("./data/GDP")
names(GDP)[2] = "rank"
GDP$rank
GDP$rank != ""
GDP[GDP$rank != ""]
GDP[GDP[GDP$rank != ""],]
GDP$rank != ""
GDP[GDP$rank != "",]
View(GDP)
GDP[GDP$rank > 0,]
GDP[GDP$rank == grep(GDP$rank, "[0-9]{1,3},]
]
""
""
grep(GDP$rank, "[0-9]{1,3}
""
""
grep(GDP$rank, "[0-9]"{1,3})
grep(GDP$rank, "[0-9]{1,3}")
grep(as.numeric(GDP$rank), "[0-9]{1,3}")
grep(as.numeric(GDP$rank), "[0-9]{1,3}")
as.numeric(GDP$rank)
grep(GDP$rank, "[0-9]")
grep(GDP$rank, "[0-9]*")
grep(as.character(GDP$rank), "[0-9]*")
grep(as.character(GDP$rank), "[0-9]*")
GDP = GDP[5:194,]
values = GDP$X.3
values = as.character(values)
values = gsub(",", "", values)
values = as.numeric(values)
mean(values, na.rm=T)
countryNames
View(GDP)
countryNames = GDP$X.3
countryNames = GDP$X.2
grep("^United", countryNames)
grep("*United", countryNames)
grep("United$", countryNames)
grep("United$", as.character(countryNames))
grep("^United", as.character(countryNames))
as.character(countryNames)
grep("^United", as.character(countryNames))
grep("^United", as.character(countryNames))
?read.csv
iconvlist()
GDP = read.csv("./data/GDP", fileEncoding="UTF-8")
countryNames = GDP$X.2
countryNames
GDP = GDP[5:194,]
countryNames = GDP$X.2
countryNames
countryNames
length(countryNames)
sum(is.na(countryNames))
sum(is.na(GDP$X.2))
is_ok_enc = function(enc) {
fileEncodings = iconvlist()
for (i in 1: length(fileEncodings)) {
GDP = read.csv("./data/GDP", fileEncoding = fileEncodings[i])
GPD = GDP[5:194,]
if (sum(is.na(GDP$X.2)) == 0) {
countryNames = GDP$X2
break
}
}
is_ok_enc = function() {
fileEncodings = iconvlist()
for (i in 1: length(fileEncodings)) {
GDP = read.csv("./data/GDP", fileEncoding = fileEncodings[i])
GPD = GDP[5:194,]
if (sum(is.na(GDP$X.2)) == 0) {
countryNames = GDP$X2
break
}
}
is_ok_enc()
""
""
""
exit
jaowiegn
)
)
is_ok_enc = function() {
fileEncodings = iconvlist()
for (i in 1: length(fileEncodings)) {
GDP = read.csv("./data/GDP", fileEncoding = fileEncodings[i])
GPD = GDP[5:194,]
if (sum(is.na(GDP$X.2)) == 0) {
countryNames = GDP$X2
break
}
}
}
is_ok_enc()
is_ok_enc
is_ok_enc()
countryNames
is_ok_enc = function() {
fileEncodings = iconvlist()
for (i in 1: length(fileEncodings)) {
GDP = read.csv("./data/GDP", fileEncoding = fileEncodings[i])
GPD = GDP[5:194,]
if (sum(is.na(GDP$X.2)) == 0) {
return GDP$X2
}
}
}
is_ok_enc = function() {
fileEncodings = iconvlist()
for (i in 1: length(fileEncodings)) {
GDP = read.csv("./data/GDP", fileEncoding = fileEncodings[i])
GPD = GDP[5:194,]
if (sum(is.na(GDP$X.2)) == 0) {
return GDP$X2
}
}
}
is_ok_enc = function() {
fileEncodings = iconvlist()
for (i in 1: length(fileEncodings)) {
GDP = read.csv("./data/GDP", fileEncoding = fileEncodings[i])
GPD = GDP[5:194,]
if (sum(is.na(GDP$X.2)) == 0) {
countryNames = GDP$X2
return countryNames
}
}
}
is_ok_enc = function() {
fileEncodings = iconvlist()
for (i in 1: length(fileEncodings)) {
GDP = read.csv("./data/GDP", fileEncoding = fileEncodings[i])
GPD = GDP[5:194,]
if (sum(is.na(GDP$X.2)) == 0) {
countryNames = GDP$X.2
return countryNames
}
}
}
is_ok_enc = function() {
fileEncodings = iconvlist()
for (i in 1: length(fileEncodings)) {
GDP = read.csv("./data/GDP", fileEncoding = fileEncodings[i])
GDP = GDP[5:194,]
if (sum(is.na(GDP$X.2)) == 0) {
countryNames = GDP$X.2
return countryNames
}
}
}
is_ok_enc = function() {
fileEncodings = iconvlist()
for (i in 1: length(fileEncodings)) {
GDP = read.csv("./data/GDP", fileEncoding = fileEncodings[i])
GDP = GDP[5:194,]
if (sum(is.na(GDP$X.2)) == 0) {
countryNames = GDP$X.2
return (countryNames)
}
}
}
is_ok_enc()
countryNames = is_ok_enc()
grep("^United", countryNames)
countryNames
length(grep("^United", countryNames))
library(qunatmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN", auto.assign=F)
sampleTimes = index(amzn)
sampleTimes
heat.colors()
library(grDevices)
pal = colorRamp(c('red', 'blue'))
pal(0)
pal(1)
pal(0.5)
pal(5)
pal(seq(0, 1, len=10))
pal(0, .1, .2)
pal(c(0, .1, .2, 1))
pal = colorRampPalette(c("red", "yellow"))
pal(2)
pal(10)
pal(10)
pal(.03)
pal = colorRamp(c('red', 'blue'))
pal(.03)
pal = colorRampPalette(c("red", "yellow"))
library(RColorBrewer)
cols = brewer.pal(3, "BuGn")
cols
pal = colorRampPalette(cols)
image(volcano, col=pal(20))
x = rnorm(10000)
y = rnorm(10000)
smoothScatter(x, y)
rgb(40, 23, 1)
rgb(0, .2, 1)
rgb(0, .2, 1, .4)
plot(x, y, pch=19)
plot(x, y, pch=19, col=rgb(0, 0, 0, 0.2))
plot(x, y, pch=19, col=rgb(0, 0, 0, 0.1))
