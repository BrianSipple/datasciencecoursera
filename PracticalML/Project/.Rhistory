crossVal = trainingData[-inTrain,]
# Verify dimensions
dim(training); dim(crossVal)
which(colnames(training) == "classe")  # 28th column is what we want to predict
M <- abs(cor(training[,-28]))
# Since every variable has a correlation of 1 with itself, we set those correlations to 0 so they're not detected
diag(M) = 0
# Now find the variables with a high correlation to each other
# From the results we get, the correlations are shown were the row of
# one variable aligns witht the column of another... and vice-versa.
which(M > 0.8, arr.ind=T)
p1
p1 <- plot(training[,11], training[,10], xlab="gyros_arm_y", ylab="gyros_arm_x")
p1
X = (.5 * training$gyros_arm_x) + (.5 * training$gyros_arm_y)
Y = (.5 * training$gyros_arm_x) - (.5 * training$gyros_arm_y)
plot(X, Y, col = rgb(0, 0, 0, .1))  # Hmm... no real difference in the variance based on this manipulation
X = (.5 * training$gyros_arm_x) * (.5 * training$gyros_arm_y)
Y = (.5 * training$gyros_arm_x) / (.5 * training$gyros_arm_y)
plot(X, Y, col=rgb(0, 0, 0, .1) )
analysis = prcomp(training[,-28], scale=T)
analysis
names(analysis)
analysis$rotation
analysis$x
analysis$sdev  # This is what we're after
variance_vector = analysis$sdev ^ 2
variance_vector
normalized_var = variance_vector / sum(variance_vector)
cumsum(normalized_var)
analysis$x[1:23]
analysis$rotate
names(analysis)
analysis$rotation
analysis$rotation[,1:23]
trainingComps =  analysis$rotation[,1:23]
View(trainingComps)
View(trainingComps)
analysis[,1:23]
analysis[1:23,]
names(analysis)
names(analysis
)
analysis$center
library(caret)
preProc = preProcess(training[,-28], method="pca", pcaComp=23)
predictions = predict(preProc, training[,-28])
predictions
trainingComps = predict(preProc, training[,-28])
modFit = train(training$classe ~., method="glm", data=trainingComps)
training$classe
trainingComps = predict(preProc, training[,-28])
trainingComps
preProc = preProcess(log10(training[,-28]+1), method="pca", pcaComp=23)
preProc = preProcess(log(training[,-28]+1), method="pca", pcaComp=23)
log10(training[,-28])
?log10
log10(training[,-28]+1)
as.numeric(training[,-28])+1
as.numeric(training[,-28])+1?
""
?apply
NAs <- apply(training, 2, function(x) { sum(is.na(x))})  # apply to 2nd margin, i.e, columns
training[, which(is.na())]
trainingData = read.csv(file="./data/training.csv", header=T, sep=",")
testingData = read.csv(file="./data/testing.csv", header=T, sep=",")
trainingData = trainingData[, c(-1, -2, -3, -4, -5)]
testingData = testingData[, c(-1, -2, -3, -4, -5)]
NAs <- apply(training, 2, function(x) { sum(is.na(x))})  # apply to 2nd margin, i.e, columns
trainingData = trainingData[, which(NAs == 0)]
testingData = testingData[, which(NAs == 0)]
testingData[, which(NAs == 0)]
trainingData[, which(NAs == 0)]
dim(trainingData)
dim(testingData)
trainingData = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", ""))
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", ""))
trainingData = trainingData[, c(-1, -2, -3, -4, -5)]
testingData = testingData[, c(-1, -2, -3, -4, -5)]
NAs <- apply(training, 2, function(x) { sum(is.na(x))})  # apply to 2nd margin, i.e, columns
trainingData = trainingData[, which(NAs == 0)]
testingData = testingData[, which(NAs == 0)]
# Verify dimensions
dim(trainingData)
dim(testingData)
trainingData = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", ""))
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", ""))
dim(trainingData)
dim(testingData)
training <- training[,c(-1,-2,-3,-4,-5)] #Delete useless variables
testing <- testing[,c(-1,-2,-3,-4,-5)]
NAs <- apply(training,2,function(x) {sum(is.na(x))})
validTrainingData <- training[,which(NAs == 0)]
validTestingData <- testing[,which(NAs == 0)]
dim(validTrainingData)
dim(trainingData)
names(trainingData)
trainingData = trainingData[, c(-1, -2, -3, -4, -5)]
testingData = testingData[, c(-1, -2, -3, -4, -5)]
NAs <- apply(training, 2, function(x) { sum(is.na(x))})  # apply to 2nd margin, i.e, columns
trainingData = trainingData[, which(NAs == 0)]
testingData = testingData[, which(NAs == 0)]
# Verify dimensions
dim(trainingData)
dim(testingData)
names(trainingData)
trainingData = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", ""))
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", ""))
View(trainingData)
View(trainingData)
trainingData = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
trainingData = trainingData[, c(-1, -2, -3, -4, -5)]
testingData = testingData[, c(-1, -2, -3, -4, -5)]
NAs <- apply(training, 2, function(x) { sum(is.na(x))})  # apply to 2nd margin, i.e, columns
trainingData = trainingData[, which(NAs == 0)]
testingData = testingData[, which(NAs == 0)]
# Verify dimensions
dim(trainingData)
dim(testingData)
names(trainingData)
View(trainingData)
View(trainingData)
trainingData = trainingData[, which(NAs >= (nrow(trainingData)/2) )]
testingData = testingData[, which(NAs >= (nrow(testingData)/2) )]
# Verify dimensions
dim(trainingData)
dim(testingData)
trainingData = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
trainingData = trainingData[, c(-1, -2, -3, -4, -5)]
testingData = testingData[, c(-1, -2, -3, -4, -5)]
NAs <- apply(training, 2, function(x) { sum(is.na(x))})  # apply to 2nd margin, i.e, columns
trainingData = trainingData[, which(NAs <= (nrow(trainingData)/2) )]
testingData = testingData[, which(NAs <= (nrow(testingData)/2) )]
# Verify dimensions
dim(trainingData)
dim(testingData)
names(trainingData)
trainingData = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
trainVec = numeric()
for (i in 1:ncol(trainingData)) {
if ( sum(is.na(trainingData[,i]) ) <= (length(trainingData[,i]) / 2) ) {
trainVec = rbind(trainVec, i)
}
}
trainingData = trainingData[, trainVec]
trainVec = numeric()
for (i in 1:92) {
if (class(trainingData[,i]) == "numeric") {
trainVec = rbind(trainVec, i)
}
}
trainVec = rbind(trainVec, 93)
# convert the training set once again
trainingData = trainingData[, trainVec]
dim(trainingData)
set.seed(250)
set.seed(300)
library(caret)
inTrain = sample(nrow(training), nrow(training) * .7)  # Using sample, we ensure that the vector indexes an even distribution of the levels in our "classe" factor
inTrain = sample(nrow(training), 3000)  # Using sample, we ensure that the vector indexes an even distribution of the levels in our "classe" factor
inTrain = sample(nrow(training), 3000)
trainingData = training[inTrain,]
inTrain = sample(nrow(training), nrow(training) * .7)
training = trainingData[inTrain,]
crossVal = trainingData[-inTrain,]
# Verify dimensions
dim(training); dim(crossVal)
trainingData = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
trainVec = numeric()
for (i in 1:ncol(trainingData)) {
if ( sum(is.na(trainingData[,i]) ) <= (length(trainingData[,i]) / 2) ) {
trainVec = rbind(trainVec, i)
}
}
trainingData = trainingData[, trainVec]
trainVec = numeric()
for (i in 1:92) {
if (class(trainingData[,i]) == "numeric") {
trainVec = rbind(trainVec, i)
}
}
trainVec = rbind(trainVec, 93)
# convert the training set once again
trainingData = trainingData[, trainVec]
dim(trainingData)
set.seed(300)
library(caret)
inTrain = createDataPartition(y = trainingData$classe,
p = .7, list=F)
inTrain = sample(nrow(trainingData), 3000)
trainingData = trainingData[inTrain,]
# Now partition further to create a cross-validation set
inTrain = sample(nrow(training), nrow(training) * .7)
training = trainingData[inTrain,]
crossVal = trainingData[-inTrain,]
# Verify dimensions
dim(training); dim(crossVal)
inTrain = sample(nrow(trainingData), nrow(trainingData) * .7)
training = trainingData[inTrain,]
crossVal = trainingData[-inTrain,]
# Verify dimensions
dim(training); dim(crossVal)
which(colnames(training) == "classe")  # 28th column is what we want to predict
set.seed(1324)
modFit = train(class~., method="rf", prox=T, data=training)
modFit = train(classe~., method="rf", prox=T, data=training)
modFit
modFit
crossValPredict <- predict(model, crossVal[,-28])
crossValPredict <- predict(modFit, crossVal[,-28])
crossValPredict
testingPredict = predict(modFit, testing[,-28])
testingPredict = predict(modFit, testingData[,-28])
?predict
testingPredict = predict(modFit, testingData[, c(-classe)]
testingPredict = predict(modFit, testingData[, c(-classe)])
testingPredict = predict(modFit, testingData[, c(-classe)])
testingPredict = predict(modFit, testingData[, c(-"classe")])
testingPredict = predict(modFit, testingData[, -c("classe")])
testingPredict = predict(modFit, testingData[, -"classe"])
which(names(testingData) == "classe")
testingPredict = predict(modFit, testingData)
testingPredict
testingData
training$classe
crossValPredicts <- predict(modFit, crossVal[,-28])
crossValPredicts
results = confusionMatrix(training$classe, crossValPredicts)
results = confusionMatrix(crossVal$classe, crossValPredicts)
results
CVresults = confusionMatrix(crossVal$classe, crossValPredicts)
CVresults
testingPredicts = predict(modFit, testingData)
testResults = confusionMatrix(testingData$classe, testingPredicts)
testingPredicts = predict(modFit, testingData$classe)
CVresults = confusionMatrix(crossVal$classe, crossValPredicts)
testResults = confusionMatrix(testingData$classe, testingPredicts)
testingPredicts
testingData$classe
names(testingData)
CVresults = confusionMatrix(crossVal$classe, crossValPredicts)
CVresults
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
names(testingData)
View(testingData)
View(testingData)
class(mtcars$am)
mtcars$am[mtcars$am == 0] <- "automatic"
mtcars$am[mtcars$am == 1] <- "manual"
mtcars$am = as.factor(mtcars$am)
mpgAuto <- mtcars$mpg[mtcars$am == "automatic"]
mpgManual <- mtcars$mpg[mtcars$am == "manual"]
comparison = t.test(x = ym, y=ya, paired=F)
comparison = t.test(x = mpgAuto, y=mpgManual, paired=F)
comparison
nrow(mtcars)
comparison$p.value
comparison$conf_int[1]
comparison
names(comparison)
comparison$esitmate[2]
comparison$estimate[2]
fit = lm(mpg ~ am, data=mtcars)
fit
fit1$coef
fit1 = lm(mpg ~ am, data=mtcars)
fit1$coef
fit2 = lm(mpg ~ wt + am, data=mtcars)
fit2
fit2$coef
fit3 = lm(mpg ~ wt + am + (wt * am), data=mtcars)
fit3$coef
varCompare <- anova(fit1, fit2, fit3)
varCompare
names(varCompare)
varCompare$Pr
varCompare$Pr(<F)
varCompare$Pr(>F)
varCompare$Pr
fit3$coe
fit3$coef
boxplot(mtcars$mpg ~ mtcars$am, col=(c(2, 3), plot=T))
boxplot(mtcars$mpg ~ mtcars$am, col=c(2, 3), plot=T)
boxplot(mtcars$mpg ~ mtcars$am, col=c("steelblue", 3), plot=T)
boxplot(mtcars$mpg ~ mtcars$am, col=c("steelblue", "lime"), plot=T)
boxplot(mtcars$mpg ~ mtcars$am, col=c("steelblue", "green"), plot=T)
plot(fit1)
boxplot(mtcars$mpg ~ mtcars$am, col=c("steelblue", "green"), plot=T)
par(mfrow = c(3, 4))
plot(fit1)
plot(fit2)
plot(fit3)
fit3
fit3$coef
fit3$coef[4]
plot(mtcars$wt, fit3$coef[2] + (mtcars$wt * fit3$coef[4]))
plot(mtcars$wt, fit3$coef[1] + fit3$coef[2] + fit3$coef[1] + (mtcars$wt * fit3$coef[4]))
plot(mtcars$wt, fit3$coef[1] + fit3$coef[2] + fit3$coef[3] + (mtcars$wt * fit3$coef[4]))
plot(mtcars$wt, fit3$coef[2] + (mtcars$wt * fit3$coef[4]))
par(mfrow = c(1, 1))
plot(mtcars$wt, fit3$coef[2] + (mtcars$wt * fit3$coef[4]))
library(dagdata)
install_github("dagdata","genomicsclass")
library(devtools)
install_github("dagdata","genomicsclass")
library(dagdata)
data(tissuesGeneExpression)
library(Biobase)
rownames(tab) <- tab$filename
t <- ExpressionSet(e, AnnotatedDataFrame(tab))
t$Tissue <- factor(t$Tissue)
colnames(t) <- paste0(t$Tissue, seq_len(ncol(t)))
library(class)
table(t$Tissue)
t <- t[,t$Tissue != "placenta"]
t$Tissue <- droplevels(t$Tissue)
table(t$Tissue)
x <- t(exprs(t))
x
?t
library(caret)
set.seed(1)
idx <- createFolds(t$Tissue, k=5)
sapply(idx, function(i) table(t$Tissue[i]))
trainingData = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
View(trainingData)
trainingData = trainingData[,-c(1, 2, 3, 4, 5)]
View(trainingData)
NA
NAs
NAs.test
NAs.test=which(countNA$testingData != 0)
countNA = data.frame(trainingData = apply(trainingData, 2, function(x) { sum(is.na(x))}),
testingData = apply(testingData, 2, function(x) { sum(is.na(x))}) )
trainingData = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
testingData = testingData[, -c(1, 2, 3, 4, 5)]
countElem = apply(trainingData, 2, function(x) { length(unique(x)) })
for (i in 1:ncol(trainingData)-1) {
if (countElem[i] > 10) {
trainingData[,i] = as.numeric(trainingData[,i])
testingData[,i] = as.numeric(testingData[,i])
}
}
for (i in 1:ncol(trainingData)-1) {
if (countElem[i] > 10) {
trainingData[,i] = as.numeric(trainingData[,i])
testingData[,i] = as.numeric(testingData[,i])
}
}
for (i in 1:(ncol(trainingData)-1)) {
if (countElem[i] > 10) {
trainingData[,i] = as.numeric(trainingData[,i])
testingData[,i] = as.numeric(testingData[,i])
}
}
for (i in 1:(ncol(trainingData)-1)) {
if (countElem[i] > 10) {
trainingData[,i] = as.numeric(trainingData[,i])
testingData[,i] = as.numeric(testingData[,i])
}
}
for (i in 1:(ncol(trainingData)-1)) {
if (countElem[i] > 10) {
trainingData[,i] = as.numeric(trainingData[,i])
testingData[,i] = as.numeric(testingData[,i])
}
}
trainingData = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
testingData = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
trainingData = trainingData[,-c(1, 2, 3, 4, 5)]
testingData = testingData[, -c(1, 2, 3, 4, 5)]
dim(trainingData)
dim(testingData)
countElem = apply(trainingData, 2, function(x) { length(unique(x)) })
for (i in 1:(ncol(trainingData)-1)) {
if (countElem[i] > 10) {
trainingData[,i] = as.numeric(trainingData[,i])
testingData[,i] = as.numeric(testingData[,i])
}
}
countNA = data.frame(trainingData = apply(trainingData, 2, function(x) { sum(is.na(x))}),
testingData = apply(testingData, 2, function(x) { sum(is.na(x))}) )
NAs = which(countNA$trainingData != 0)
NAs.test=which(countNA$testingData != 0)
out = union(NAs, NAs.test)
out
NAs = which(countNA$trainingData != 0)
NAs.test=which(countNA$testingData != 0)
out = union(NAs, NAs.test)
training = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
testing = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
training = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
testing = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
training = training[,-c(1, 2, 3, 4, 5)]
testing = testing[, -c(1, 2, 3, 4, 5)]
# turn classes of variables into their appropiate class by reasoning with their unique counts
countElem = apply(training, 2, function(x) { length(unique(x)) })
for (i in 1:(ncol(training)-1)) {
if (countElem[i] > 10) {
training[,i] = as.numeric(training[,i])
testing[,i] = as.numeric(testing[,i])
}
}
# Remove variables that are all NAs in the test data set:
countNA = data.frame(training = apply(training, 2, function(x) { sum(is.na(x))}),
testing = apply(testing, 2, function(x) { sum(is.na(x))}) )
NAs = which(countNA$training != 0)
NAs.test=which(countNA$testing != 0)
out = union(NAs, NAs.test)
training = training[,-out]
testing = testing[,-out]
set.seed(1)
folds = createFolds(y=train$classe, k=10, list=T, returnTrain = T)
folds = createFolds(y=training$classe, k=10, list=T, returnTrain = T)
pred = factor(rep("A", nrow(training)), levels=levels(train$classe))
folds
mu = mean(missClassFold)
missClass = sum(pred != training$classe) / nrow(training) * 100
pred = factor(rep("A", nrow(training)), levels=levels(training$classe))
# Use predictive algorithm random forest to train model and predict outcome for the k-folds
library(randomForest)
for (i in 1:length(folds)) {
print(i)
model = randomForest(classe~., data=training[folds[[i]], -1])
pred[-folds[[i]]] = predict(model, training[-folds[[i]], -1])
}
training = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
setwd("/Users/BrianSipple/Development/R/datasciencecoursera/PracticalML/Project/")
training = read.csv(file="./data/training.csv", header=T, na.strings=c("NA", " "))
testing = read.csv(file="./data/testing.csv", header=T, na.strings=c("NA", " "))
training = training[,-c(1, 2, 3, 4, 5)]
testing = testing[, -c(1, 2, 3, 4, 5)]
# turn classes of variables into their appropiate class by reasoning with their unique counts
countElem = apply(training, 2, function(x) { length(unique(x)) })
for (i in 1:(ncol(training)-1)) {
if (countElem[i] > 10) {
training[,i] = as.numeric(training[,i])
testing[,i] = as.numeric(testing[,i])
}
}
countNA = data.frame(training = apply(training, 2, function(x) { sum(is.na(x))}),
testing = apply(testing, 2, function(x) { sum(is.na(x))}) )
NAs = which(countNA$training != 0)
NAs.test=which(countNA$testing != 0)
out = union(NAs, NAs.test)
training = training[,-out]
testing = testing[,-out]
# Split the data for k-folds cross-validation
set.seed(1)
library(caret)
folds = createFolds(y=training$classe, k=10, list=T, returnTrain = T)
pred = factor(rep("A", nrow(training)), levels=levels(training$classe))
# Use predictive algorithm random forest to train model and predict outcome for the k-folds
library(randomForest)
for (i in 1:length(folds)) {
print(i)
model = randomForest(classe~., data=training[folds[[i]], -1])
pred[-folds[[i]]] = predict(model, train[-folds[[i]], -1])
}
install.packages("TeX")
install.packages("tex")
for (i in 1:length(folds)) {
print(i)
model = randomForest(classe~., data=training[folds[[i]], -1])
pred[-folds[[i]]] = predict(model, training[-folds[[i]], -1])
}
missClass = sum(pred != training$classe) / nrow(training) * 100
missClass
# compute the mean and standard deviate of each misclassification error of the k-fold
missClassFold = c()
for (i in 1:length(folds)) {
missClassFold = c(missClassFold,
sum(pred[-folds[[i]]] != training$classe[-folds[[i]]]) /nrow(training) - length(folds[[i]])) * 100 )
}
for (i in 1:length(folds)) {
missClassFold = c(missClassFold,
sum(pred[-folds[[i]]] != training$classe[-folds[[i]]]) /nrow(training) - length(folds[[i]])) * 100 )
}
for (i in 1:length(folds)) {
missClassFold = c(missClassFold,
sum(pred[-folds[[i]]] != training$classe[-folds[[i]]]) /nrow(training) - length(folds[[i]]) * 100 )
}
mu = mean(missClassFold)
sdev = sd(missClassFold)
# We can form a 95% Confidence interval for the missclassification error
CI = [mu-2*sdev, mu+2*sdev]
#classify the test data:
testing$new_window = factor(testing$new_window, levels = c('no', 'yes'))
model = randomForest(class~. data = training[,-1])
answers = predict(model, testing[,-c(ncol(test))])
answers = predict(model, testing[,-c(ncol(testing))])
pml_write_files = function(x) {
n = length(x)
for (i in 1:n) {
filename = paste0("problem_id_", i, ".txt")
write.table(x[i], file=filename, quote=F, row.names=F, col.names=F)
}
}
mu-2*sdev
mu+2*sdev
answers
testing$classe
testing
names(testing)
training
pml_write_files(answers)
